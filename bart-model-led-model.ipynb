{"cells":[{"cell_type":"code","execution_count":null,"metadata":{"_cell_guid":"b1076dfc-b9ad-4769-8c92-a6c4dae69d19","_uuid":"8f2839f25d086af736a60e9eeb907d3b93b6e0e5","trusted":true},"outputs":[],"source":["!pip install transformers"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["from transformers import AutoTokenizer, BartForConditionalGeneration\n","\n","model = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-cnn\")\n","tokenizer = AutoTokenizer.from_pretrained(\"facebook/bart-large-cnn\")"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["article  = \"\"\"\n","Chennai rains: The India Meteorological Department (IMD) warned against heavy rains in Tamil Nadu and issued yellow alert for October 19. \n","IMD issued orange alert for Saturday in Thiruvallur, Chennai, Chengalpattu, Kancheepuram, Villupuram, Kallakkurichi, \n","Thiruvannamalai, Ranipettai, Vellore, Tiruppattur, Krishnagiri, Dharmapuri, Cuddalore, Nagapattinam, Thiruvarur, \n","Thanjavur, Pudukottai, Sivagangai, Ramanathapuram, Madurai, Kanyakumari districts of Tamil Nadu, and Puducherry.\n","\n","IMD in its latest weather bulletin said, ‚ÄúScattered to Fairly widespread light to moderate rainfall over Tamil Nadu, \n","Puducherry & Karaikal, Kerala & Mahe, Lakshadweep, Karnataka; Isolated to scattered light to moderate rainfall over \n","rest of the region‚Äù until October 25.\n","\n","The weather department in its press release dated October 18 predicted ‚Äúisolated heavy rainfall‚Äù in Tamil Nadu, \n","Puducherry and Karaikal on October 20, 21 and 24; in Karnataka on October 20 and 21; and in Coastal Andhra Pradesh \n","and Yanam on October 24. IMD issued orange alert in Tamil Nadu's capital, Chengalpattu, Tiruvannamalai and in more \n","districts today.\n","\n","There are three districts of Tamil Nadu that are on orange alert for heavy rains for the next few hours, namely \n","Vandalur, Thiruporur and Cheyur. IMD issued yellow alert for Maduranthakam, Chengalpattu, Tirukazhukundram, \n","Tambaram, Nemili and Arakkonam districts.\n","\n","Tamil Nadu's Tiruvannamalai district recorded heavy rainfall in the 24-hour period, from 8:30 am of October 17 till \n","the same time next day, IMD said.\n","\n","Over heavy rains that wreaked havoc in the area leading to flood-like situation in the state, Tamil Nadu Chief Minister \n","Thiru MK Stalin in a post on X (formerly Twitter) expressed gratitude to all those volunteers who helped in safe eviction \n","of residents. The post reads, ‚ÄúA small token of our gratitude for the tremendous service of the sanitation workers \n","who have been roaming around to protect lakhs of people of the capital city from the brunt of the Northeast Monsoon!‚Äù\n","\"\"\"\n","\n","inputs = tokenizer([article], max_length=1024, return_tensors=\"pt\")\n","\n","\n","# Generate Summary\n","summary_ids = model.generate(inputs[\"input_ids\"], num_beams=4, min_length=100, max_length=1024)\n","summary = tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n","print(summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["model1 = BartForConditionalGeneration.from_pretrained(\"facebook/bart-large-xsum\")\n","tokenizer1 = AutoTokenizer.from_pretrained(\"facebook/bart-large-xsum\")\n"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["article = \"\"\"\n","## Artificial Intelligence and Its Impact on Society\n","\n","### Introduction\n","Artificial Intelligence (AI) has become a transformative technology that is shaping nearly every aspect of modern life. From the way we interact with devices to how businesses operate, AI is changing the dynamics of numerous industries. The concept of AI is not new; it dates back to the 1950s when researchers first began exploring the potential of machines to mimic human intelligence. However, recent advances in computing power, big data, and machine learning algorithms have accelerated AI's development and deployment across the globe.\n","\n","In this article, we will explore what AI is, how it has evolved over the years, its various applications, and the potential benefits and risks it poses to society. We will also discuss the ethical considerations that come with the widespread adoption of AI technologies and the steps needed to ensure a balanced and fair AI-driven future.\n","\n","### Understanding AI: Definitions and Concepts\n","AI refers to the development of computer systems that can perform tasks typically requiring human intelligence. These tasks include reasoning, learning, problem-solving, perception, and language understanding. AI can be categorized into two main types: *narrow AI* and *general AI*.\n","\n","- *Narrow AI* is designed for specific tasks and is currently the most prevalent form of AI. Examples include virtual assistants like Siri and Alexa, recommendation algorithms on streaming services, and image recognition software.\n","- *General AI* is a theoretical form of AI that would have the cognitive abilities of a human across a wide range of activities. General AI could understand, learn, and apply knowledge to perform any intellectual task. Although general AI remains a concept in research, it is often portrayed in science fiction as a potential future of AI development.\n","\n","### The Evolution of AI: A Historical Perspective\n","The history of AI can be divided into several phases:\n","\n","1. *The Early Days (1950s-1970s):* The concept of AI began to gain traction in the 1950s with pioneers like Alan Turing, who proposed the Turing Test to assess a machine's ability to exhibit intelligent behavior. Early AI research focused on symbolic reasoning, with limited computational power available. Despite some initial successes, the complexity of AI challenges led to periods known as \"AI winters,\" where funding and interest dwindled.\n","\n","2. *The Rise of Machine Learning (1980s-2000s):* The 1980s saw a shift from rule-based AI systems to machine learning, where computers were trained to recognize patterns in data. Techniques like neural networks gained popularity, allowing for more adaptive systems. The development of the internet and the availability of large datasets in the 1990s further fueled machine learning research.\n","\n","3. *The Deep Learning Era (2010s-Present):* The advent of deep learning has been a game-changer for AI. Leveraging complex neural networks with multiple layers, deep learning has enabled breakthroughs in computer vision, natural language processing, and speech recognition. Companies like Google, Facebook, and OpenAI have developed state-of-the-art models that can analyze images, translate languages, and even play games at superhuman levels.\n","\n","### Key Applications of AI in Modern Society\n","AI is being applied in various sectors, fundamentally changing how tasks are performed and decisions are made. Some of the key applications of AI include:\n","\n","- *Healthcare:* AI is revolutionizing healthcare through applications like predictive diagnostics, personalized treatment plans, and robotic surgery. AI algorithms can analyze medical images to detect abnormalities and predict patient outcomes, making healthcare more efficient and accurate.\n","\n","- *Finance:* In the financial sector, AI is used for algorithmic trading, fraud detection, credit scoring, and customer service chatbots. By analyzing large volumes of transaction data, AI systems can identify fraudulent activities and provide real-time risk assessments.\n","\n","- *Transportation:* AI plays a crucial role in autonomous vehicles and traffic management systems. Companies like Tesla and Waymo are developing self-driving cars that rely on AI to interpret sensor data and make driving decisions. AI also optimizes logistics and supply chain management by predicting demand and improving route planning.\n","\n","- *Education:* AI-powered tools are being used in education to create personalized learning experiences. Adaptive learning platforms can adjust to the needs of each student, providing customized exercises and feedback. AI can also assist teachers with grading and administrative tasks, freeing up time for student engagement.\n","\n","- *Entertainment and Media:* AI is at the heart of recommendation systems used by platforms like Netflix, Spotify, and YouTube. By analyzing user behavior, these systems suggest content that aligns with user preferences. AI is also used in content creation, such as generating music, art, and even articles like this one.\n","\n","### Benefits of AI: A Transformational Force\n","AI offers numerous benefits that can significantly enhance productivity, efficiency, and quality of life. Some of these benefits include:\n","\n","- *Automation of Repetitive Tasks:* AI can automate routine and repetitive tasks, allowing humans to focus on more creative and strategic work. This has applications across industries, from manufacturing to customer service.\n","\n","- *Enhanced Decision-Making:* AI can process vast amounts of data and uncover insights that humans might miss. This ability helps businesses make better decisions, optimize operations, and improve customer satisfaction.\n","\n","- *Improved Accuracy and Precision:* In fields like medicine and engineering, AI algorithms can perform tasks with a level of precision that is difficult for humans to achieve. This leads to better outcomes, such as fewer errors in medical diagnoses or more precise manufacturing processes.\n","\n","- *24/7 Availability:* Unlike humans, AI systems do not require breaks or sleep. This makes them ideal for roles like customer support, where 24/7 availability is a significant advantage.\n","\n","### Challenges and Risks of AI\n","Despite its many benefits, AI also poses several challenges and risks that need to be addressed:\n","\n","- *Job Displacement:* The automation of tasks by AI could lead to significant job losses, particularly in sectors like manufacturing, retail, and customer service. While AI creates new job opportunities in tech and data analysis, there is a need for retraining and reskilling programs for those whose jobs are at risk.\n","\n","- *Bias and Fairness:* AI systems are only as good as the data they are trained on. If the training data contains biases, the AI system can perpetuate or even amplify these biases. This has serious implications, particularly in areas like hiring, criminal justice, and credit scoring.\n","\n","- *Privacy Concerns:* The use of AI often involves collecting and analyzing large amounts of personal data. This raises concerns about data privacy and security, especially when sensitive information is involved. Regulations like GDPR aim to protect user data, but the rapid advancement of AI requires constant vigilance.\n","\n","- *Security Threats:* AI can be weaponized in cyber-attacks, such as creating more sophisticated phishing schemes or automating hacking attempts. The rise of deepfake technology, where AI generates realistic fake videos or audio, also presents a challenge for distinguishing truth from falsehood.\n","\n","### Ethical Considerations in AI\n","As AI becomes more pervasive, it raises ethical questions that society must grapple with:\n","\n","- *Transparency:* AI algorithms can be complex and difficult to interpret, making it challenging to understand how they arrive at their decisions. This lack of transparency can be problematic in situations where accountability is crucial.\n","\n","- *Accountability:* When an AI system makes a decision that affects people's lives, such as approving a loan or diagnosing a medical condition, it is essential to establish who is responsible for the outcome. Developers, companies, and users must be accountable for the actions of AI systems.\n","\n","- *AI in Warfare:* The use of AI in autonomous weapons is a contentious issue. While AI can enhance military capabilities, it also raises concerns about the potential for misuse and the ethical implications of machines making life-and-death decisions.\n","\n","### The Future of AI: Opportunities and Challenges Ahead\n","Looking ahead, the future of AI is both promising and uncertain. Advances in AI could lead to groundbreaking innovations in areas like drug discovery, climate change modeling, and human-computer interaction. However, achieving a balance between innovation and ethical considerations will be key to ensuring that AI serves humanity's best interests.\n","\n","Governments, companies, and researchers must collaborate to create regulations and standards that promote responsible AI development. Investment in AI education and training will be crucial for preparing the workforce for an AI-driven future. Additionally, fostering a culture of transparency and inclusivity will help address the challenges and risks associated with AI.\n","\n","### Conclusion\n","Artificial Intelligence is more than just a technological advancement; it is a force that is reshaping society. While AI has the potential to bring about tremendous benefits, it also comes with challenges that must be carefully managed. By fostering a collaborative and ethical approach to AI development, we can ensure that this transformative technology contributes to a better future for all.\n","\"\"\"\n","\n","inputs = tokenizer1([article], max_length=1024, return_tensors=\"pt\")\n","\n","\n","# Generate Summary\n","summary_ids = model1.generate(inputs[\"input_ids\"], num_beams=4, min_length=0, max_length=1024)\n","summary = tokenizer1.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]\n","print(summary)"]},{"cell_type":"markdown","metadata":{},"source":["large xsum  - 1024  In our series of articles, we look at how artificial intelligence (AI) has evolved over the years and how it is being applied in the world of business and the arts, as well as the ethical considerations that come with the widespread adoption of AI technologies and the steps needed to ensure a balanced and fair AI-driven future. (Closed by the International Academy of Artificial Intelligence (IAI) in New York, 12 February 2017.)... (Open by the IAI in the IAU in the London, London, and Paris, 14 February 2017)."]},{"cell_type":"markdown","metadata":{},"source":["large cnn - 1024 Artificial Intelligence (AI) has become a transformative technology that is shaping nearly every aspect of modern life. From the way we interact with devices to how businesses operate, AI is changing the dynamics of numerous industries. In this article, we will explore what AI is, how it has evolved over the years, its various applications, and the potential benefits and risks it poses to society. We will also discuss the ethical considerations that come with the widespread adoption of AI technologies and the steps needed to ensure a balanced and fair AI-driven future."]},{"cell_type":"markdown","metadata":{},"source":["large cnn - 2048 Artificial Intelligence (AI) has become a transformative technology that is shaping nearly every aspect of modern life. From the way we interact with devices to how businesses operate, AI is changing the dynamics of numerous industries. In this article, we will explore what AI is, how it has evolved over the years, its various applications, and the potential benefits and risks it poses to society. We will also discuss the ethical considerations that come with the widespread adoption of AI technologies and the steps needed to ensure a balanced and fair AI-driven future."]},{"cell_type":"code","execution_count":null,"metadata":{"trusted":true},"outputs":[],"source":["print(model.name_or_path)"]},{"cell_type":"code","execution_count":1,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T18:51:36.926198Z","iopub.status.busy":"2024-10-19T18:51:36.925608Z","iopub.status.idle":"2024-10-19T18:51:54.786187Z","shell.execute_reply":"2024-10-19T18:51:54.784908Z","shell.execute_reply.started":"2024-10-19T18:51:36.926141Z"},"trusted":true},"outputs":[{"data":{"text/html":["<div>\n","<style scoped>\n","    .dataframe tbody tr th:only-of-type {\n","        vertical-align: middle;\n","    }\n","\n","    .dataframe tbody tr th {\n","        vertical-align: top;\n","    }\n","\n","    .dataframe thead th {\n","        text-align: right;\n","    }\n","</style>\n","<table border=\"1\" class=\"dataframe\">\n","  <thead>\n","    <tr style=\"text-align: right;\">\n","      <th></th>\n","      <th>rating</th>\n","      <th>title</th>\n","      <th>text</th>\n","      <th>images</th>\n","      <th>asin</th>\n","      <th>parent_asin</th>\n","      <th>user_id</th>\n","      <th>timestamp</th>\n","      <th>helpful_vote</th>\n","      <th>verified_purchase</th>\n","    </tr>\n","  </thead>\n","  <tbody>\n","    <tr>\n","      <th>0</th>\n","      <td>3</td>\n","      <td>Smells like gasoline! Going back!</td>\n","      <td>First &amp; most offensive: they reek of gasoline ...</td>\n","      <td>[{'small_image_url': 'https://m.media-amazon.c...</td>\n","      <td>B083NRGZMM</td>\n","      <td>B083NRGZMM</td>\n","      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n","      <td>2022-07-18 22:58:37.948</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>1</th>\n","      <td>1</td>\n","      <td>Didn‚Äôt work at all lenses loose/broken.</td>\n","      <td>These didn‚Äôt work. Idk if they were damaged in...</td>\n","      <td>[]</td>\n","      <td>B07N69T6TM</td>\n","      <td>B07N69T6TM</td>\n","      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n","      <td>2020-06-20 18:42:29.731</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>2</th>\n","      <td>5</td>\n","      <td>Excellent!</td>\n","      <td>I love these. They even come with a carry case...</td>\n","      <td>[]</td>\n","      <td>B01G8JO5F2</td>\n","      <td>B01G8JO5F2</td>\n","      <td>AFKZENTNBQ7A7V7UXW5JJI6UGRYQ</td>\n","      <td>2018-04-07 09:23:37.534</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>3</th>\n","      <td>5</td>\n","      <td>Great laptop backpack!</td>\n","      <td>I was searching for a sturdy backpack for scho...</td>\n","      <td>[]</td>\n","      <td>B001OC5JKY</td>\n","      <td>B001OC5JKY</td>\n","      <td>AGGZ357AO26RQZVRLGU4D4N52DZQ</td>\n","      <td>2010-11-20 18:41:35.000</td>\n","      <td>18</td>\n","      <td>True</td>\n","    </tr>\n","    <tr>\n","      <th>4</th>\n","      <td>5</td>\n","      <td>Best Headphones in the Fifties price range!</td>\n","      <td>I've bought these headphones three times becau...</td>\n","      <td>[]</td>\n","      <td>B013J7WUGC</td>\n","      <td>B07CJYMRWM</td>\n","      <td>AG2L7H23R5LLKDKLBEF2Q3L2MVDA</td>\n","      <td>2023-02-17 02:39:41.238</td>\n","      <td>0</td>\n","      <td>True</td>\n","    </tr>\n","  </tbody>\n","</table>\n","</div>"],"text/plain":["   rating                                        title  \\\n","0       3            Smells like gasoline! Going back!   \n","1       1      Didn‚Äôt work at all lenses loose/broken.   \n","2       5                                   Excellent!   \n","3       5                       Great laptop backpack!   \n","4       5  Best Headphones in the Fifties price range!   \n","\n","                                                text  \\\n","0  First & most offensive: they reek of gasoline ...   \n","1  These didn‚Äôt work. Idk if they were damaged in...   \n","2  I love these. They even come with a carry case...   \n","3  I was searching for a sturdy backpack for scho...   \n","4  I've bought these headphones three times becau...   \n","\n","                                              images        asin parent_asin  \\\n","0  [{'small_image_url': 'https://m.media-amazon.c...  B083NRGZMM  B083NRGZMM   \n","1                                                 []  B07N69T6TM  B07N69T6TM   \n","2                                                 []  B01G8JO5F2  B01G8JO5F2   \n","3                                                 []  B001OC5JKY  B001OC5JKY   \n","4                                                 []  B013J7WUGC  B07CJYMRWM   \n","\n","                        user_id               timestamp  helpful_vote  \\\n","0  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2022-07-18 22:58:37.948             0   \n","1  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2020-06-20 18:42:29.731             0   \n","2  AFKZENTNBQ7A7V7UXW5JJI6UGRYQ 2018-04-07 09:23:37.534             0   \n","3  AGGZ357AO26RQZVRLGU4D4N52DZQ 2010-11-20 18:41:35.000            18   \n","4  AG2L7H23R5LLKDKLBEF2Q3L2MVDA 2023-02-17 02:39:41.238             0   \n","\n","   verified_purchase  \n","0               True  \n","1               True  \n","2               True  \n","3               True  \n","4               True  "]},"execution_count":1,"metadata":{},"output_type":"execute_result"}],"source":["import pandas as pd\n","\n","\n","\n","file_path = '/kaggle/input/amazon-product/data1.jsonl'\n","\n","\n","df = pd.read_json(file_path, lines=True)\n","\n","\n","df.head()\n"]},{"cell_type":"code","execution_count":14,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T19:09:51.115265Z","iopub.status.busy":"2024-10-19T19:09:51.114561Z","iopub.status.idle":"2024-10-19T19:09:51.126162Z","shell.execute_reply":"2024-10-19T19:09:51.124526Z","shell.execute_reply.started":"2024-10-19T19:09:51.115207Z"},"trusted":true},"outputs":[],"source":["def collect_reviews_by_asin(df, asin):\n","    reviews = df[df['asin'] == asin]['text']\n","    return ' '.join(reviews.tolist())\n","\n","def summarize_chunk(text):\n","    print(\"first chunk\");\n","    inputs = tokenizer([text], max_length=1024, return_tensors=\"pt\", truncation=True)\n","    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=20, max_length=100)\n","    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n"]},{"cell_type":"code","execution_count":15,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T19:09:57.153411Z","iopub.status.busy":"2024-10-19T19:09:57.152853Z","iopub.status.idle":"2024-10-19T19:09:57.360646Z","shell.execute_reply":"2024-10-19T19:09:57.359090Z","shell.execute_reply.started":"2024-10-19T19:09:57.153331Z"},"trusted":true},"outputs":[],"source":["\n","asin_to_summarize = 'B07N69T6TM'\n","\n","collected_reviews = collect_reviews_by_asin(df, asin_to_summarize)\n","\n","\n","# if not collected_reviews:\n","#     print(\"No reviews found for this product.\")\n","# else:\n","#     # Summarize the collected reviews directly\n","#     summary = summarize_chunk(collected_reviews)  # Directly pass the collected reviews to summarize\n","\n","#     print(\"Final Summary:\\n\", summary)"]},{"cell_type":"code","execution_count":18,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T19:12:44.391722Z","iopub.status.busy":"2024-10-19T19:12:44.391123Z","iopub.status.idle":"2024-10-19T19:15:06.108462Z","shell.execute_reply":"2024-10-19T19:15:06.106938Z","shell.execute_reply.started":"2024-10-19T19:12:44.391668Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["first chunk\n","first chunk\n","first chunk\n","first chunk\n"]},{"name":"stderr","output_type":"stream","text":["Input ids are automatically padded from 109 to 1024 to be a multiple of `config.attention_window`: 1024\n"]},{"name":"stdout","output_type":"stream","text":["first chunk\n","Final Summary:\n","  these were given to my seven year old daughter to help her learn to use binocs . \n"," they were great initially , good fit for her and decent magnification and focus to help her learn to use binocs. Unfortunately in less than 2 months they no longer focus. Buyer beware , you get what you pay for. Didn‚Äôt hold up more than 2 months. Didn‚Äôt hold up more than 2 months. Didn‚Äôt hold up more than 2 months  we got these as a gift for our 2yo since he likes to pretend to use binoculars all the time .  so far we haven‚Äôt had any issues with them .                                                               Knockulars are a great toy for young children to enjoy with their parents .                                                                                     the boy love them , They were exploring as soon as they got them.  the best way to get them out side in Frisch air and sunshine üëçüèº my 4 year old grandson loved it. he put them on his neck immediately and walked around looking at his world.  making lots of memories together.day.<br /><br /> well worth the money and well made binoculars. for the price it‚Äôs great.   these are not much more than \"pretend\" binoculars for a small child to play make-believe.front lenses are screwed too far forward , they catch on the outer casing ( the colored part) and both pieces of casing pop off completely.front lenses are screwed too far forward , they catch on the outer casing ( the colored part) and both pieces of casing pop off completely.front lenses are screwed too far forward , they catch on the outer casing ( the colored part)\n"]}],"source":["import textwrap\n","\n","asin_to_summarize = 'B07N69T6TM'\n","\n","\n","collected_reviews = collect_reviews_by_asin(df, asin_to_summarize)\n","\n","if not collected_reviews:\n","    print(\"No reviews found for this product.\")\n","else:\n","   \n","    chunks = textwrap.wrap(collected_reviews, 800)\n","    \n","\n","    first_five_chunks = chunks[:10]\n","\n","   \n","    summaries = [summarize_chunk(chunk) for chunk in first_five_chunks]\n","    \n","    final_summary = \" \".join(summaries)\n","\n","    print(\"Final Summary:\\n\", final_summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["unique_asin_count = df['asin'].nunique()\n","print(\"Number of unique ASINs:\", unique_asin_count)\n","\n","asin_counts = df['asin'].value_counts()\n","\n","# Print the counts of each unique ASIN\n","print(\"Unique ASINs and their counts:\")\n","print(asin_counts)"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["\n","import textwrap\n","def collect_reviews_by_asin(df, asin):\n","    reviews = df[df['asin'] == asin]['text']\n","    # print(reviews)\n","    return ' '.join(reviews.tolist())  \n","\n","\n","def summarize_reviews(reviews):\n","    print(len(reviews))\n","    print(\"the above is the overall combination of review\")\n","    inputs = tokenizer([reviews], max_length=1024, return_tensors=\"pt\", truncation=True)\n","    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=50, max_length=200)\n","    summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","    return summary\n","\n","\n","asin_to_summarize = 'B013J7WUGC'  \n","reviews = collect_reviews_by_asin(df, asin_to_summarize)\n","\n","def summarize_chunk(text):\n","    inputs = tokenizer([text], max_length=1024, return_tensors=\"pt\", truncation=True)\n","    summary_ids = model.generate(inputs['input_ids'], num_beams=4, min_length=50, max_length=200)\n","    return tokenizer.decode(summary_ids[0], skip_special_tokens=True)\n","\n","\n","chunks = textwrap.wrap(reviews, 800)\n","\n","\n","summaries = [summarize_chunk(chunk) for chunk in chunks]\n","final_summary = \" \".join(summaries)\n","\n","print(\"Final Summary:\\n\", final_summary)"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["from transformers import pipeline\n","\n","import numpy as np"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["\n","summarizer = pipeline(\"summarization\", model=\"facebook/bart-large-cnn\")"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["from transformers import BartTokenizer\n"]},{"cell_type":"code","execution_count":null,"metadata":{"jupyter":{"source_hidden":true},"trusted":true},"outputs":[],"source":["def chunk_text(text, max_length=1024):\n","  \n","    tokens = tokenizer.encode(text, return_tensors='pt')\n","  \n","    return [tokens[0][i:i + max_length].tolist() for i in range(0, tokens.size(1), max_length) if i + max_length <= tokens.size(1)]\n","\n","\n","def summarize_product_reviews(asin):\n","\n","    product_reviews = df[df['asin'] == asin]['text'].tolist()\n","    \n","    if not product_reviews:\n","        return \"No reviews found for this product.\"\n","  \n","    combined_reviews = \" \".join(product_reviews)\n","    \n"," \n","    chunks = chunk_text(combined_reviews)\n","    \n","    if not chunks:\n","        return \"No valid chunks to summarize.\"\n","\n","    summaries = []\n","    for chunk in chunks:\n","     \n","        chunk_text_decoded = tokenizer.decode(chunk, skip_special_tokens=True)\n","        summary = summarizer(chunk_text_decoded, max_length=150, min_length=30, do_sample=False)\n","        summaries.append(summary[0]['summary_text'])\n","    \n","\n","    final_summary = \" \".join(summaries)\n","    return final_summary\n","\n","\n","asin = 'B013J7WUGC'  \n","summary = summarize_product_reviews(asin)\n","print(\"Final Summary:\")\n","print(summary)"]},{"cell_type":"code","execution_count":9,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T18:44:40.671859Z","iopub.status.busy":"2024-10-19T18:44:40.670964Z","iopub.status.idle":"2024-10-19T18:44:53.281354Z","shell.execute_reply":"2024-10-19T18:44:53.279755Z","shell.execute_reply.started":"2024-10-19T18:44:40.671800Z"},"jupyter":{"source_hidden":true},"trusted":true},"outputs":[{"name":"stderr","output_type":"stream","text":["Some weights of PegasusForConditionalGeneration were not initialized from the model checkpoint at google/pegasus-xsum and are newly initialized: ['model.decoder.embed_positions.weight', 'model.encoder.embed_positions.weight']\n","You should probably TRAIN this model on a down-stream task to be able to use it for predictions and inference.\n"]}],"source":["from transformers import AutoTokenizer, PegasusForConditionalGeneration\n","\n","model = PegasusForConditionalGeneration.from_pretrained(\"google/pegasus-xsum\")\n","tokenizer = AutoTokenizer.from_pretrained(\"google/pegasus-xsum\")"]},{"cell_type":"code","execution_count":11,"metadata":{"collapsed":true,"execution":{"iopub.execute_input":"2024-10-19T18:44:58.331102Z","iopub.status.busy":"2024-10-19T18:44:58.330266Z","iopub.status.idle":"2024-10-19T18:44:58.870934Z","shell.execute_reply":"2024-10-19T18:44:58.868633Z","shell.execute_reply.started":"2024-10-19T18:44:58.331025Z"},"jupyter":{"outputs_hidden":true},"trusted":true},"outputs":[{"ename":"IndexError","evalue":"index out of range in self","output_type":"error","traceback":["\u001b[0;31m---------------------------------------------------------------------------\u001b[0m","\u001b[0;31mIndexError\u001b[0m                                Traceback (most recent call last)","Cell \u001b[0;32mIn[11], line 4\u001b[0m\n\u001b[1;32m      1\u001b[0m inputs \u001b[38;5;241m=\u001b[39m tokenizer(collected_reviews, max_length\u001b[38;5;241m=\u001b[39m\u001b[38;5;241m1024\u001b[39m, return_tensors\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mpt\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m      3\u001b[0m \u001b[38;5;66;03m# Generate Summary\u001b[39;00m\n\u001b[0;32m----> 4\u001b[0m summary_ids \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mgenerate\u001b[49m\u001b[43m(\u001b[49m\u001b[43minputs\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43minput_ids\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      5\u001b[0m tokenizer\u001b[38;5;241m.\u001b[39mbatch_decode(summary_ids, skip_special_tokens\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, clean_up_tokenization_spaces\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mFalse\u001b[39;00m)[\u001b[38;5;241m0\u001b[39m]\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:1864\u001b[0m, in \u001b[0;36mGenerationMixin.generate\u001b[0;34m(self, inputs, generation_config, logits_processor, stopping_criteria, prefix_allowed_tokens_fn, synced_gpus, assistant_model, streamer, negative_prompt_ids, negative_prompt_attention_mask, **kwargs)\u001b[0m\n\u001b[1;32m   1860\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m`attention_mask` passed to `generate` must be 2D.\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n\u001b[1;32m   1862\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;129;01min\u001b[39;00m model_kwargs:\n\u001b[1;32m   1863\u001b[0m     \u001b[38;5;66;03m# if model is encoder decoder encoder_outputs are created and added to `model_kwargs`\u001b[39;00m\n\u001b[0;32m-> 1864\u001b[0m     model_kwargs \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_prepare_encoder_decoder_kwargs_for_generation\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1865\u001b[0m \u001b[43m        \u001b[49m\u001b[43minputs_tensor\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_kwargs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mmodel_input_name\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mgeneration_config\u001b[49m\n\u001b[1;32m   1866\u001b[0m \u001b[43m    \u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1868\u001b[0m \u001b[38;5;66;03m# 5. Prepare `input_ids` which will be used for auto-regressive generation\u001b[39;00m\n\u001b[1;32m   1869\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mconfig\u001b[38;5;241m.\u001b[39mis_encoder_decoder:\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/generation/utils.py:512\u001b[0m, in \u001b[0;36mGenerationMixin._prepare_encoder_decoder_kwargs_for_generation\u001b[0;34m(self, inputs_tensor, model_kwargs, model_input_name, generation_config)\u001b[0m\n\u001b[1;32m    510\u001b[0m encoder_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mreturn_dict\u001b[39m\u001b[38;5;124m\"\u001b[39m] \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mTrue\u001b[39;00m\n\u001b[1;32m    511\u001b[0m encoder_kwargs[model_input_name] \u001b[38;5;241m=\u001b[39m inputs_tensor\n\u001b[0;32m--> 512\u001b[0m model_kwargs[\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mencoder_outputs\u001b[39m\u001b[38;5;124m\"\u001b[39m]: ModelOutput \u001b[38;5;241m=\u001b[39m \u001b[43mencoder\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mencoder_kwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    514\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m model_kwargs\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py:743\u001b[0m, in \u001b[0;36mPegasusEncoder.forward\u001b[0;34m(self, input_ids, attention_mask, head_mask, inputs_embeds, output_attentions, output_hidden_states, return_dict)\u001b[0m\n\u001b[1;32m    740\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m inputs_embeds \u001b[38;5;129;01mis\u001b[39;00m \u001b[38;5;28;01mNone\u001b[39;00m:\n\u001b[1;32m    741\u001b[0m     inputs_embeds \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_tokens(input_ids) \u001b[38;5;241m*\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39membed_scale\n\u001b[0;32m--> 743\u001b[0m embed_pos \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membed_positions\u001b[49m\u001b[43m(\u001b[49m\u001b[43minput_shape\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    745\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m inputs_embeds \u001b[38;5;241m+\u001b[39m embed_pos\n\u001b[1;32m    747\u001b[0m hidden_states \u001b[38;5;241m=\u001b[39m nn\u001b[38;5;241m.\u001b[39mfunctional\u001b[38;5;241m.\u001b[39mdropout(hidden_states, p\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdropout, training\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mtraining)\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1553\u001b[0m, in \u001b[0;36mModule._wrapped_call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1551\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_compiled_call_impl(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs)  \u001b[38;5;66;03m# type: ignore[misc]\u001b[39;00m\n\u001b[1;32m   1552\u001b[0m \u001b[38;5;28;01melse\u001b[39;00m:\n\u001b[0;32m-> 1553\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_call_impl\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/module.py:1562\u001b[0m, in \u001b[0;36mModule._call_impl\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1557\u001b[0m \u001b[38;5;66;03m# If we don't have any hooks, we want to skip the rest of the logic in\u001b[39;00m\n\u001b[1;32m   1558\u001b[0m \u001b[38;5;66;03m# this function, and just call forward.\u001b[39;00m\n\u001b[1;32m   1559\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m (\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_forward_pre_hooks\n\u001b[1;32m   1560\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_backward_pre_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_backward_hooks\n\u001b[1;32m   1561\u001b[0m         \u001b[38;5;129;01mor\u001b[39;00m _global_forward_hooks \u001b[38;5;129;01mor\u001b[39;00m _global_forward_pre_hooks):\n\u001b[0;32m-> 1562\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mforward_call\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m   1564\u001b[0m \u001b[38;5;28;01mtry\u001b[39;00m:\n\u001b[1;32m   1565\u001b[0m     result \u001b[38;5;241m=\u001b[39m \u001b[38;5;28;01mNone\u001b[39;00m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/utils/_contextlib.py:116\u001b[0m, in \u001b[0;36mcontext_decorator.<locals>.decorate_context\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    113\u001b[0m \u001b[38;5;129m@functools\u001b[39m\u001b[38;5;241m.\u001b[39mwraps(func)\n\u001b[1;32m    114\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mdecorate_context\u001b[39m(\u001b[38;5;241m*\u001b[39margs, \u001b[38;5;241m*\u001b[39m\u001b[38;5;241m*\u001b[39mkwargs):\n\u001b[1;32m    115\u001b[0m     \u001b[38;5;28;01mwith\u001b[39;00m ctx_factory():\n\u001b[0;32m--> 116\u001b[0m         \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mfunc\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43margs\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mkwargs\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/transformers/models/pegasus/modeling_pegasus.py:103\u001b[0m, in \u001b[0;36mPegasusSinusoidalPositionalEmbedding.forward\u001b[0;34m(self, input_ids_shape, past_key_values_length)\u001b[0m\n\u001b[1;32m     99\u001b[0m bsz, seq_len \u001b[38;5;241m=\u001b[39m input_ids_shape[:\u001b[38;5;241m2\u001b[39m]\n\u001b[1;32m    100\u001b[0m positions \u001b[38;5;241m=\u001b[39m torch\u001b[38;5;241m.\u001b[39marange(\n\u001b[1;32m    101\u001b[0m     past_key_values_length, past_key_values_length \u001b[38;5;241m+\u001b[39m seq_len, dtype\u001b[38;5;241m=\u001b[39mtorch\u001b[38;5;241m.\u001b[39mlong, device\u001b[38;5;241m=\u001b[39m\u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mweight\u001b[38;5;241m.\u001b[39mdevice\n\u001b[1;32m    102\u001b[0m )\n\u001b[0;32m--> 103\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[38;5;28;43msuper\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mforward\u001b[49m\u001b[43m(\u001b[49m\u001b[43mpositions\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/modules/sparse.py:164\u001b[0m, in \u001b[0;36mEmbedding.forward\u001b[0;34m(self, input)\u001b[0m\n\u001b[1;32m    163\u001b[0m \u001b[38;5;28;01mdef\u001b[39;00m \u001b[38;5;21mforward\u001b[39m(\u001b[38;5;28mself\u001b[39m, \u001b[38;5;28minput\u001b[39m: Tensor) \u001b[38;5;241m-\u001b[39m\u001b[38;5;241m>\u001b[39m Tensor:\n\u001b[0;32m--> 164\u001b[0m     \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mF\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m    165\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mmax_norm\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m    166\u001b[0m \u001b[43m        \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mnorm_type\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","File \u001b[0;32m/opt/conda/lib/python3.10/site-packages/torch/nn/functional.py:2267\u001b[0m, in \u001b[0;36membedding\u001b[0;34m(input, weight, padding_idx, max_norm, norm_type, scale_grad_by_freq, sparse)\u001b[0m\n\u001b[1;32m   2261\u001b[0m     \u001b[38;5;66;03m# Note [embedding_renorm set_grad_enabled]\u001b[39;00m\n\u001b[1;32m   2262\u001b[0m     \u001b[38;5;66;03m# XXX: equivalent to\u001b[39;00m\n\u001b[1;32m   2263\u001b[0m     \u001b[38;5;66;03m# with torch.no_grad():\u001b[39;00m\n\u001b[1;32m   2264\u001b[0m     \u001b[38;5;66;03m#   torch.embedding_renorm_\u001b[39;00m\n\u001b[1;32m   2265\u001b[0m     \u001b[38;5;66;03m# remove once script supports set_grad_enabled\u001b[39;00m\n\u001b[1;32m   2266\u001b[0m     _no_grad_embedding_renorm_(weight, \u001b[38;5;28minput\u001b[39m, max_norm, norm_type)\n\u001b[0;32m-> 2267\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtorch\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43membedding\u001b[49m\u001b[43m(\u001b[49m\u001b[43mweight\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;28;43minput\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mpadding_idx\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mscale_grad_by_freq\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43msparse\u001b[49m\u001b[43m)\u001b[49m\n","\u001b[0;31mIndexError\u001b[0m: index out of range in self"]}],"source":["inputs = tokenizer(collected_reviews, max_length=1024, return_tensors=\"pt\")\n","\n","\n","summary_ids = model.generate(inputs[\"input_ids\"])\n","tokenizer.batch_decode(summary_ids, skip_special_tokens=True, clean_up_tokenization_spaces=False)[0]"]},{"cell_type":"code","execution_count":4,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T18:52:54.363377Z","iopub.status.busy":"2024-10-19T18:52:54.362860Z","iopub.status.idle":"2024-10-19T18:53:02.313783Z","shell.execute_reply":"2024-10-19T18:53:02.312271Z","shell.execute_reply.started":"2024-10-19T18:52:54.363334Z"},"trusted":true},"outputs":[],"source":["import torch\n","f4rom transformers import AutoTokenizer, LEDForConditionalGeneration"]},{"cell_type":"code","execution_count":5,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T18:53:32.071654Z","iopub.status.busy":"2024-10-19T18:53:32.070638Z","iopub.status.idle":"2024-10-19T18:53:34.211438Z","shell.execute_reply":"2024-10-19T18:53:34.210022Z","shell.execute_reply.started":"2024-10-19T18:53:32.071595Z"},"trusted":true},"outputs":[],"source":["model = LEDForConditionalGeneration.from_pretrained(\"allenai/led-large-16384-arxiv\")\n","tokenizer = AutoTokenizer.from_pretrained(\"allenai/led-large-16384-arxiv\")"]},{"cell_type":"code","execution_count":20,"metadata":{"execution":{"iopub.execute_input":"2024-10-19T20:08:59.844851Z","iopub.status.busy":"2024-10-19T20:08:59.843252Z","iopub.status.idle":"2024-10-19T20:09:18.595760Z","shell.execute_reply":"2024-10-19T20:09:18.594206Z","shell.execute_reply.started":"2024-10-19T20:08:59.844787Z"},"trusted":true},"outputs":[{"name":"stdout","output_type":"stream","text":["Generated Summary:\n","  these are perfect little binoculars for my 5 year old son.  \n"," they fit perfectly in his little 2 yr old hands.  \n"," they can focus across the lake and he loves them.    \n"," these are\n"]}],"source":["\n","if isinstance(collected_reviews, list):\n","    collected_reviews = \" \".join(collected_reviews)\n","\n","\n","inputs = tokenizer.encode(collected_reviews, return_tensors=\"pt\")\n","global_attention_mask = torch.zeros_like(inputs)\n","global_attention_mask[:, 0] = 1\n","\n","\n","summary_ids = model.generate(inputs, global_attention_mask=global_attention_mask, num_beams=3, max_length=100)\n","summary = tokenizer.decode(summary_ids[0], skip_special_tokens=True, clean_up_tokenization_spaces=True)\n","\n","print(\"Generated Summary:\\n\", summary)\n"]}],"metadata":{"kaggle":{"accelerator":"none","dataSources":[{"datasetId":5908069,"sourceId":9668567,"sourceType":"datasetVersion"}],"dockerImageVersionId":30786,"isGpuEnabled":false,"isInternetEnabled":true,"language":"python","sourceType":"notebook"},"kernelspec":{"display_name":"Python 3","language":"python","name":"python3"},"language_info":{"codemirror_mode":{"name":"ipython","version":3},"file_extension":".py","mimetype":"text/x-python","name":"python","nbconvert_exporter":"python","pygments_lexer":"ipython3","version":"3.10.14"}},"nbformat":4,"nbformat_minor":4}
